{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RwSpJlUdVg_"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d01-bUfjdc7g",
    "outputId": "68c1b724-b7b9-45b1-8b57-69cd3155cbfc"
   },
   "outputs": [],
   "source": [
    "#!pip install matcouply tensorly tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bI7H0-6WjI5p",
    "outputId": "45fa290e-1cc6-4564-ef6d-49009e034bac"
   },
   "outputs": [],
   "source": [
    "#!pip install scanpy sccellfie cell2cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nzSkIE4dVhA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tqdm import tqdm\n",
    "import matcouply\n",
    "\n",
    "from copy import deepcopy\n",
    "from matcouply.decomposition import cmf_aoadmm\n",
    "from matcouply.penalties import MatricesPenalty, NonNegativity,Parafac2\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXxrTIJbjQjJ"
   },
   "outputs": [],
   "source": [
    "import sccellfie\n",
    "import scanpy as sc\n",
    "import cell2cell as c2c\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2025-07-03'\n",
    "folder = './Mes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"/lustre/scratch126/cellgen/vento/hm11/with_Erick/adata_mes_all_harm_anno_p1.h5ad\", backed='r')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oSLmkpTjI9o",
    "outputId": "befd305e-118b-4e2d-c95a-36fbcdf73561"
   },
   "outputs": [],
   "source": [
    "adata2 = sc.read(\"/lustre/scratch126/cellgen/vento/hm11/with_Erick/cdata_thy_noStressEmb.h5ad\", backed='r')\n",
    "adata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapper = adata2.obs[['sample', 'age_group']].drop_duplicates().set_index('sample')['age_group'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([s in age_mapper.keys() for s in adata.obs['sample'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['age_group'] = adata.obs['sample'].map(age_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = ['mes_CYGB', 'mes_KCNB2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['sample'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['age_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups = ['9-10', '11-13', '14-15', '16-17', '20']\n",
    "def assign_group(x):\n",
    "    for g in new_groups:\n",
    "        if str(x) in g.split('-'):\n",
    "            return g\n",
    "        if str(x) == '12':\n",
    "            return '11-13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['age_group2'] = adata.obs['pcw'].apply(lambda x: assign_group(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['age_group2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs['celltype'].isin(celltypes)].to_memory()\n",
    "adata.X = adata.layers['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCCM_ROPrPWO"
   },
   "outputs": [],
   "source": [
    "sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_og = adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kB107F370S9"
   },
   "outputs": [],
   "source": [
    "#sc.pp.highly_variable_genes(adata, n_top_genes=250, flavor=\"seurat\")\n",
    "#adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProteinCodingGenes(adata, group='protein_coding'):\n",
    "    '''return protein-coding genes in adata\n",
    "    example: getProteinCodingGenes(adata)'''\n",
    "    import pandas as pd\n",
    "    coding_genes = pd.read_csv('/lustre/scratch126/cellgen/vento/hm11/with_Erick/gene_symbol_type.tsv', sep='\\t', header=None)\n",
    "    cgenes = coding_genes.loc[coding_genes[2] == 'protein_coding',1].tolist()\n",
    "    cgenesInData_logic = adata.var_names.isin(cgenes)\n",
    "    print(f'[INFO] coding genes found in adata {cgenesInData_logic.sum()} ({len(cgenes)} total protein-coding genes)')\n",
    "    return adata.var.loc[cgenesInData_logic,:].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpPercGroup(adata, groups, min_cells = 20,  min_pct = 0.1):\n",
    "    '''return expressed cells percentage and number per group, output genes and groups\n",
    "    sf.getExpPercGroup(adata[adata.obs['celltype'].isin(['thy_TH_processing', 'thy_Lumen-forming'])], ['age_group','celltype','karyotype'])'''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df = adata.obs[groups].agg('_'.join, axis=1).rename('agg_col').reset_index()\n",
    "    agg_dict = df.groupby('agg_col')['index'].apply(list).to_dict()\n",
    "    perc_dict = {}\n",
    "    exp_dict = {}\n",
    "    for k,v in agg_dict.items():\n",
    "        siz = np.size(adata[v,:].X, axis=0)\n",
    "        exp = np.sum(adata[v,:].X > 0, axis=0).A1 \n",
    "        perc_dict[k] = exp/siz\n",
    "        exp_dict[k] = exp\n",
    "        \n",
    "    p = pd.DataFrame.from_dict(perc_dict).set_index(adata.var_names)\n",
    "    e = pd.DataFrame.from_dict(exp_dict).set_index(adata.var_names)\n",
    "    HI_GENES = ((e >= min_cells) * (p >= min_pct)).any(axis=1)\n",
    "    HI_GENES = HI_GENES[HI_GENES].index.tolist()\n",
    "    print(f'[INFO] {len(agg_dict.keys())} aggs using {groups} at min_cells={min_cells},  min_pct={min_pct}. {len(HI_GENES)} genes')\n",
    "    return HI_GENES, list(agg_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_encoding = getProteinCodingGenes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:, protein_encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_genes, groups = getExpPercGroup(adata, ['age_group2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:, filter_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = 'age_group2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UE_3vvEqHyj",
    "outputId": "64bdd1a7-299b-4b28-9b02-3f53d6ea8a33"
   },
   "outputs": [],
   "source": [
    "agg_dfs = []\n",
    "for group in tqdm(new_groups): # sorted(adata.obs[groups].unique(), key= lambda x: int(x))\n",
    "    print(group)\n",
    "    adata_tmp = adata[adata.obs[groups] == group, :] # adata.var[\"highly_variable\"]\n",
    "    agg = sccellfie.expression.aggregation.agg_expression_cells(adata_tmp, \"celltype\", layer=None, gene_symbols=None, agg_func='trimean')\n",
    "    agg_dfs.append(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xyt18_XV1Dw"
   },
   "outputs": [],
   "source": [
    "# Drop all zero genes\n",
    "for i, agg in enumerate(agg_dfs):\n",
    "    if i == 0:\n",
    "        agg_filter = (agg.sum(axis=0) > 0)\n",
    "    else:\n",
    "        agg_filter = agg_filter | (agg.sum(axis=0) > 0)\n",
    "\n",
    "agg_dfs = [agg.T[agg_filter].T for agg in agg_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = [agg.columns.tolist() for agg in agg_dfs]\n",
    "cell_names = agg_dfs[0].index.tolist()\n",
    "time_names = new_groups\n",
    "all(lst == gene_names[0] for lst in gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{folder}/tPARAFAC2_tensor_indexes-{date}.pkl', 'wb') as f:\n",
    "    pickle.dump([cell_names, gene_names, time_names], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RV8iyAe_s-y_",
    "outputId": "243b041b-73d5-489a-d30f-2f7e9ac8e12e"
   },
   "outputs": [],
   "source": [
    "tensor = tl.tensor([df.values.T for df in agg_dfs]).T\n",
    "tensor.shape # cell types by genes by time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBTLJDfB-eT8"
   },
   "outputs": [],
   "source": [
    "# mu = adata.X.mean()\n",
    "# print(mu)\n",
    "# tensor = tensor / (tensor + mu) # regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PM7LQ9EPdVhA"
   },
   "source": [
    "# Custom penalty class for matCoupLy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6izMxxTsdVhB"
   },
   "outputs": [],
   "source": [
    "class myTemporalSmoothnessPenalty(MatricesPenalty):\n",
    "    def __init__(\n",
    "        self, smoothness_l, aux_init=\"random_uniform\", dual_init=\"random_uniform\"\n",
    "    ):\n",
    "        super().__init__(aux_init=aux_init, dual_init=dual_init)\n",
    "        self.smoothness_l = smoothness_l\n",
    "\n",
    "    @copy_ancestor_docstring\n",
    "    def factor_matrices_update(self, factor_matrices, feasibility_penalties, auxes):\n",
    "\n",
    "        # factor_matrices: factor + mus\n",
    "        # feasability_penalties: rhos\n",
    "        # auxes: -||-\n",
    "\n",
    "        # rhs = [rhos[i] * factor_matrices[i] for i in range(len(B_is))]\n",
    "\n",
    "        B_is = factor_matrices\n",
    "        rhos = feasibility_penalties\n",
    "\n",
    "        rhs = [rhos[i] * factor_matrices[i] for i in range(len(B_is))]\n",
    "\n",
    "        # Construct matrix A to peform gaussian elimination on\n",
    "\n",
    "        A = np.zeros((len(B_is), len(B_is)))\n",
    "\n",
    "        for i in range(len(B_is)):\n",
    "            for j in range(len(B_is)):\n",
    "                if i == j:\n",
    "                    A[i, j] = 4 * self.smoothness_l + rhos[i]\n",
    "                elif i == j - 1 or i == j + 1:\n",
    "                    A[i, j] = -2 * self.smoothness_l\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        A[0, 0] -= 2 * self.smoothness_l\n",
    "        A[len(B_is) - 1, len(B_is) - 1] -= 2 * self.smoothness_l\n",
    "\n",
    "        # Peform GE\n",
    "\n",
    "        for k in range(1, A.shape[-1]):\n",
    "            m = A[k, k - 1] / A[k - 1, k - 1]\n",
    "\n",
    "            A[k, :] = A[k, :] - m * A[k - 1, :]\n",
    "            rhs[k] = rhs[k] - m * rhs[k - 1]  # Also update the respective rhs!\n",
    "\n",
    "        # Back-substitution\n",
    "\n",
    "        new_ZBks = [np.empty_like(B_is[i]) for i in range(len(B_is))]\n",
    "\n",
    "        new_ZBks[-1] = rhs[-1] / A[-1, -1]\n",
    "        q = new_ZBks[-1]\n",
    "\n",
    "        for i in range(A.shape[-1] - 2, -1, -1):\n",
    "            q = (rhs[i] - A[i, i + 1] * q) / A[i, i]\n",
    "            new_ZBks[i] = q\n",
    "\n",
    "        return new_ZBks\n",
    "\n",
    "    def penalty(self, x):\n",
    "        penalty = 0\n",
    "        for x1, x2 in zip(x[:-1], x[1:]):\n",
    "            penalty += np.sum((x1 - x2) ** 2)\n",
    "        return self.smoothness_l * penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe1LazCDdVhB"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16JG0I6NdVhB"
   },
   "outputs": [],
   "source": [
    "data = tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-59qTSrAyDe",
    "outputId": "d4161620-c5e1-4b06-cf59-63f7726a8d67"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpzJvY1BdVhB"
   },
   "source": [
    "# Fitting a PARAFAC2 model with AO-ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4ff21d9595a145b19ed4dc51c9906c92",
      "612076666c92457fa109174f9d85a428",
      "5b09d3d3ad44450e84488082f0decf5d",
      "4e2446e87d794612b55f9fbaa6187308",
      "64e29ac4084d4f62bddca42674a15d9d",
      "715ea9a29154483b8715c25f384abe1f",
      "127a842a2b6c41b3831f3e7e09e957f1",
      "1816513dcc2c4230b2ac3bf9d2f610ad",
      "e786935c14a645f9a34c8b55cdd3691d",
      "b1b012a02caa498494b949b60cf3a156",
      "d55b929b7db9436d87d37cd1f64dbd99"
     ]
    },
    "id": "5HdhEBqfdVhB",
    "outputId": "2103e402-b02d-400f-9358-b84da862a0a7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run X initializations of tPARAFAC2\n",
    "initializations = 10\n",
    "rank = 6\n",
    "factors_list = []\n",
    "diagnostics_list = []\n",
    "\n",
    "for init_no in tqdm(range(initializations)):\n",
    "\n",
    "    input_data = deepcopy(data)\n",
    "\n",
    "    (weights, (D, B, A)), diagnostics = cmf_aoadmm(\n",
    "        matrices=input_data.T, # Has to be .T because of tensorly\n",
    "        rank=rank, # No of components\n",
    "        regs=[\n",
    "            [NonNegativity()], # Mode-3 constraints\n",
    "            [Parafac2(),myTemporalSmoothnessPenalty(smoothness_l=200)], # Mode-2 constraints\n",
    "            [NonNegativity()], # Mode-1 constraints\n",
    "        ],\n",
    "        l1_penalty=[0, 0, 20], # Lasso penalties for each mode [mode-3,mode-2,mode-1] / sparsity # [0, 0, 20],\n",
    "        l2_penalty=[20, 0, 0], # Ridge penalties for each mode [mode-3,mode-2,mode-1] / low values\n",
    "        return_errors=True,\n",
    "        n_iter_max=8000,\n",
    "        inner_n_iter_max=5, # inner admm iters\n",
    "        tol=1e-8,\n",
    "        absolute_tol=1e-10,\n",
    "        feasibility_tol=1e-6,\n",
    "        inner_tol=1e-5,\n",
    "        verbose=500, # print intermediate run info every 500 iters\n",
    "        random_state=init_no # if you would like to fix the initiliaizations\n",
    "    )\n",
    "    factors_list.append([D,B,A])\n",
    "    diagnostics_list.append(diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(diagnostics_per_init,factors_per_init,zoom_in_to_first_n=50,filename=None):\n",
    "    '''\n",
    "    Plot convergence of all initializations in the following format:\n",
    "\n",
    "    rel_sse | parafac2 constraint feasiblity gap\n",
    "    -----------------------------------------------\n",
    "    total_loss | temporal smoothness feasibility gap\n",
    "\n",
    "    Degenerate cases are not plotted.\n",
    "    '''\n",
    "\n",
    "    inits2ignore = [False] * len(factors_per_init)\n",
    "    \n",
    "    for init_no in range(len(factors_per_init)):\n",
    "        \n",
    "        if check_degenerate(factors_per_init[init_no]) == True:\n",
    "            \n",
    "            inits2ignore[init_no] = True\n",
    "            print(f'Initialization {init_no} is degenerate and will not be plotted.')\n",
    "\n",
    "    fig, axs = plt.subplot_mosaic([['rec_errors','parafac2_feasibility'],['reg_loss','smoothness_feasiblity']],figsize=(12,6))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    max_iters = max([diag.n_iter for diag in diagnostics_per_init])\n",
    "\n",
    "    all_min_cur_error = []\n",
    "    all_min_cur_parafac2_feasibility = []\n",
    "    all_min_cur_reg_loss = []\n",
    "    all_min_cur_smoothness_feasibility = []\n",
    "\n",
    "    all_max_cur_error = []\n",
    "    all_max_cur_parafac2_feasibility = []\n",
    "    all_max_cur_reg_loss = []\n",
    "    all_max_cur_smoothness_feasibility = []\n",
    "\n",
    "    all_median_cur_error = []\n",
    "    all_median_cur_parafac2_feasibility = []\n",
    "    all_median_cur_reg_loss = []\n",
    "    all_median_cur_smoothness_feasibility = []\n",
    "\n",
    "    for iter_no in range(max_iters):\n",
    "\n",
    "        # Form a list of all diagnostics for this initialization at the current iteration\n",
    "\n",
    "        cur_rer_errors = []\n",
    "        cur_parafac2_feasibility = []\n",
    "        cur_reg_loss = []\n",
    "        cur_smoothness_feasibility = []\n",
    "\n",
    "        for init_no in range(len(factors_per_init)):\n",
    "\n",
    "            if inits2ignore[init_no] == False and iter_no <= diagnostics_per_init[init_no].n_iter:\n",
    "\n",
    "                cur_rer_errors.append(diagnostics_per_init[init_no].rec_errors[iter_no])\n",
    "                # cur_rer_errors.append(diagnostics_per_init[init_no].un_rec_errors[iter_no])\n",
    "                cur_parafac2_feasibility.append(diagnostics_per_init[init_no].feasibility_gaps[iter_no][1][0])\n",
    "                try:\n",
    "                    cur_smoothness_feasibility.append(diagnostics_per_init[init_no].feasibility_gaps[iter_no][1][1])\n",
    "                except:\n",
    "                    pass\n",
    "                cur_reg_loss.append(diagnostics_per_init[init_no].regularized_loss[iter_no])\n",
    "\n",
    "        all_min_cur_error.append(min(cur_rer_errors))\n",
    "        all_max_cur_error.append(max(cur_rer_errors))\n",
    "        all_median_cur_error.append(np.median(cur_rer_errors))\n",
    "\n",
    "        all_min_cur_parafac2_feasibility.append(min(cur_parafac2_feasibility))\n",
    "        all_max_cur_parafac2_feasibility.append(max(cur_parafac2_feasibility))\n",
    "        all_median_cur_parafac2_feasibility.append(np.median(cur_parafac2_feasibility))\n",
    "\n",
    "        all_min_cur_reg_loss.append(min(cur_reg_loss))\n",
    "        all_max_cur_reg_loss.append(max(cur_reg_loss))\n",
    "        all_median_cur_reg_loss.append(np.median(cur_reg_loss))\n",
    "\n",
    "        try:\n",
    "            all_min_cur_smoothness_feasibility.append(min(cur_smoothness_feasibility))\n",
    "            all_max_cur_smoothness_feasibility.append(max(cur_smoothness_feasibility))\n",
    "            all_median_cur_smoothness_feasibility.append(np.median(cur_smoothness_feasibility))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Plot the area between min and max errors and the median error\n",
    "    axs['rec_errors'].fill_between(range(max_iters),all_min_cur_error,all_max_cur_error,color='tab:blue',alpha=0.2)\n",
    "    axs['rec_errors'].plot(range(max_iters),all_median_cur_error,color='tab:blue',label='rec_errors')\n",
    "    axs['rec_errors'].set_title('Relative SSE')\n",
    "\n",
    "    # Plot the area between min and max parafac2 feasibility and the median parafac2 feasibility\n",
    "    try:\n",
    "        axs['parafac2_feasibility'].fill_between(range(max_iters),all_min_cur_parafac2_feasibility,all_max_cur_parafac2_feasibility,color='tab:orange',alpha=0.2)\n",
    "        axs['parafac2_feasibility'].plot(range(max_iters),all_median_cur_parafac2_feasibility,color='tab:orange',label='parafac2_feasibility')\n",
    "        axs['parafac2_feasibility'].set_title('Parafac2 feasibility')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Plot the area between min and max reg loss and the median reg loss\n",
    "    axs['reg_loss'].fill_between(range(max_iters),all_min_cur_reg_loss,all_max_cur_reg_loss,color='tab:green',alpha=0.2)\n",
    "    axs['reg_loss'].plot(range(max_iters),all_median_cur_reg_loss,color='tab:green',label='reg_loss')\n",
    "    axs['reg_loss'].set_title('Total loss')\n",
    "\n",
    "    # Plot the area between min and max smoothness feasibility and the median smoothness feasibility\n",
    "    try:\n",
    "        axs['smoothness_feasiblity'].fill_between(range(max_iters),all_min_cur_smoothness_feasibility,all_max_cur_smoothness_feasibility,color='tab:red',alpha=0.2)\n",
    "        axs['smoothness_feasiblity'].plot(range(max_iters),all_median_cur_smoothness_feasibility,color='tab:red',label='smoothness_feasiblity')\n",
    "        axs['smoothness_feasiblity'].set_title('Smoothness feasibility')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    zoomed_in_rec_error = fig.add_axes([0.285,0.765,0.2,0.2])\n",
    "\n",
    "    zoomed_in_rec_error.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_error[:zoom_in_to_first_n],all_max_cur_error[:zoom_in_to_first_n],color='tab:blue',alpha=0.2)\n",
    "    zoomed_in_rec_error.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_error[:zoom_in_to_first_n],color='tab:blue',label='rec_errors')\n",
    "    zoomed_in_rec_error.set_yticks([0.2,0.4,0.6,0.8])\n",
    "\n",
    "    try:\n",
    "        zoomed_in_parafac2_feasibility = fig.add_axes([0.778,0.765,0.2,0.2])\n",
    "        zoomed_in_parafac2_feasibility.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_parafac2_feasibility[:zoom_in_to_first_n],all_max_cur_parafac2_feasibility[:zoom_in_to_first_n],color='tab:orange',alpha=0.2)\n",
    "        zoomed_in_parafac2_feasibility.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_parafac2_feasibility[:zoom_in_to_first_n],color='tab:orange',label='parafac2_feasibility')\n",
    "        zoomed_in_parafac2_feasibility.set_yticks([0.2,0.4,0.6,0.8])\n",
    "        zoomed_in_parafac2_feasibility.set_yscale('log')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    zoomed_in_reg_loss = fig.add_axes([0.285,0.278,0.2,0.2])\n",
    "    zoomed_in_reg_loss.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_reg_loss[:zoom_in_to_first_n],all_max_cur_reg_loss[:zoom_in_to_first_n],color='tab:green',alpha=0.2)\n",
    "    zoomed_in_reg_loss.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_reg_loss[:zoom_in_to_first_n],color='tab:green',label='reg_loss')\n",
    "    zoomed_in_reg_loss.set_yscale('log')\n",
    "\n",
    "    try:\n",
    "        zoomed_in_smoothness_feasiblity = fig.add_axes([0.778,0.278,0.2,0.2])\n",
    "        zoomed_in_smoothness_feasiblity.fill_between(range(max_iters)[:zoom_in_to_first_n],all_min_cur_smoothness_feasibility[:zoom_in_to_first_n],all_max_cur_smoothness_feasibility[:zoom_in_to_first_n],color='tab:red',alpha=0.2)\n",
    "        zoomed_in_smoothness_feasiblity.plot(range(max_iters)[:zoom_in_to_first_n],all_median_cur_smoothness_feasibility[:zoom_in_to_first_n],color='tab:red',label='smoothness_feasiblity')\n",
    "        zoomed_in_smoothness_feasiblity.set_yscale('log')\n",
    "    except:\n",
    "        pass\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "from tensorly.cp_tensor import CPTensor\n",
    "from tlviz.factor_tools import degeneracy_score\n",
    "\n",
    "# Function for checking degeneracy\n",
    "\n",
    "def check_degenerate(factors,threshold=-0.85):\n",
    "    '''\n",
    "    Check solution for degenerecy (just a wrapper for tlviz degeneracy score).\n",
    "    '''\n",
    "\n",
    "    A = factors[0]\n",
    "    B = factors[1]\n",
    "    D = factors[2]\n",
    "\n",
    "    new_B = np.zeros((len(B)*B[0].shape[0],B[0].shape[-1]))\n",
    "\n",
    "    for r in range(B[0].shape[-1]):\n",
    "        \n",
    "        b_temp = B[0][:,r]\n",
    "\n",
    "        for k in range(1,len(B)):\n",
    "\n",
    "            b_temp = np.concatenate((b_temp,B[k][:,r]))\n",
    "\n",
    "        new_B[:,r] = b_temp\n",
    "\n",
    "    decomp = CPTensor((np.array([1.0]*rank),(A,new_B,D)))\n",
    "\n",
    "    if degeneracy_score(decomp) < threshold: return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(diagnostics_list,factors_list,10, f'{folder}/{date}-Plot-Convergence.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ktm1bhyOdVhC"
   },
   "source": [
    "# Choose the best run according to loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6Ahtw3bdVhC"
   },
   "outputs": [],
   "source": [
    "best_factors = factors_list[0]\n",
    "best_error = diagnostics_list[0].regularized_loss[-1]\n",
    "\n",
    "if len(factors_list) > 1:\n",
    "    for init_no in range(1,len(best_factors)):\n",
    "        if diagnostics_list[init_no].regularized_loss[-1] < best_error:\n",
    "            best_factors = factors_list[init_no]\n",
    "            best_errors = diagnostics_list[init_no].regularized_loss[-1]\n",
    "else:\n",
    "    best_factors = factors_list[0]\n",
    "    best_errors = diagnostics_list[0].regularized_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the complex structure\n",
    "with open(f'{folder}/tPARAFAC2_factors-{date}.pkl', 'wb') as f:\n",
    "    pickle.dump(best_factors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the complex structure\n",
    "with open(f'{folder}/tPARAFAC2_factors-{date}.pkl', 'rb') as f:\n",
    "    best_factors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gE2aHBxKdcGD"
   },
   "outputs": [],
   "source": [
    "D, B, A = best_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEvjuDI2mmuU",
    "outputId": "4096249e-2934-42e1-ddf6-e13ecf663627"
   },
   "outputs": [],
   "source": [
    "D.shape, len(B), B[0].shape, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chHPf4d35S3U"
   },
   "outputs": [],
   "source": [
    "def plot_Bs(est_B, J, K, rank, filename):\n",
    "    \"\"\"\n",
    "    Plot B factors computed by PARAFAC2.\n",
    "    \n",
    "    Parameters:\n",
    "    est_B (list of np.array): List of B factor matrices\n",
    "    rank (int): Number of factors (previously no_of_concepts)\n",
    "    J (int): Number of variables\n",
    "    K (int): Number of time points\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, rank, figsize=(4*rank, 10))\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('B factors', fontsize=40)\n",
    "    plt.subplots_adjust(wspace=0.3, top=0.85)\n",
    "\n",
    "    # Normalize the B factors\n",
    "    for r in range(rank):\n",
    "        b_temp = est_B[0][:, r]\n",
    "        for k in range(1, K):\n",
    "            b_temp = np.concatenate((b_temp, est_B[k][:, r]))\n",
    "        \n",
    "        norm = np.linalg.norm(b_temp)\n",
    "        for k in range(K):\n",
    "            est_B[k][:, r] = est_B[k][:, r] / norm\n",
    "\n",
    "    for pattern_no in range(rank):\n",
    "        B_2_plot = form_plotting_B(est_B, pattern_no, J, K)\n",
    "\n",
    "        ax = axes[pattern_no] if rank > 1 else axes\n",
    "        im = sns.heatmap(B_2_plot.T, \n",
    "                         ax=ax,\n",
    "                         cbar=(pattern_no == rank-1),  # Only show colorbar for the last plot\n",
    "                         cmap='Reds',\n",
    "                         #vmin=-0.4, \n",
    "                         #vmax=0.4\n",
    "                        )\n",
    "        \n",
    "        ax.tick_params(left=False, bottom=True)\n",
    "        ax.patch.set_edgecolor('black')\n",
    "        ax.set_yticks([])\n",
    "        ax.patch.set_linewidth(1.5)\n",
    "        ax.set_xticks(np.arange(0.5, adata.obs['age_group2'].unique().shape[0]+0.5, 1), labels=new_groups,fontsize=3.5, rotation=90)\n",
    "        ax.set_xlabel(r'time',fontsize=16)\n",
    "        ax.set_ylabel(r'genes',fontsize=16)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f'Factor {pattern_no+1}',pad=3.5,fontsize=36)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "\n",
    "def form_plotting_B(B_list, pattern_no, J, K):\n",
    "    \"\"\"\n",
    "    Takes as input a list of B factors and returns a matrix containing\n",
    "    the pattern_no-th column of each factor matrix.\n",
    "    \"\"\"\n",
    "    matrix2return = np.zeros((K, J))\n",
    "    for k in range(K):\n",
    "        matrix2return[k, :] = B_list[k][:, pattern_no].T\n",
    "    return matrix2return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8FVb_fENfff"
   },
   "outputs": [],
   "source": [
    "def euclidean_normalization(matrix):\n",
    "    # Calculate the Euclidean norm for each gene (row)\n",
    "    norms = np.linalg.norm(matrix, axis=0, keepdims=True)\n",
    "\n",
    "    # Normalize each gene by its Euclidean norm\n",
    "    normalized_matrix = matrix / norms\n",
    "\n",
    "    return normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "7KUH1Z1h6NUJ",
    "outputId": "c0ef6cde-ef45-4110-b44c-22a21efec0a5"
   },
   "outputs": [],
   "source": [
    "plot_Bs(B, data.shape[1], data.shape[2], rank, f'{folder}/Plot-Factors-B.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "dU4YnO2ZC-4F",
    "outputId": "67ff007f-1fb7-4a82-e3fe-e8360f019cae"
   },
   "outputs": [],
   "source": [
    "mode1_df = pd.DataFrame(A,index=agg_dfs[0].index, columns=[f'Factor {i+1}' for i in range(rank)])\n",
    "sns.heatmap(mode1_df, cmap='Reds', vmin=0)\n",
    "plt.savefig(f'{folder}/Plot-Factors-A.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmin_func(data):\n",
    "        return -np.abs(data).max()\n",
    "    \n",
    "def vmax_func(data):\n",
    "    return np.abs(data).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_genes = dict()\n",
    "percentile = 99\n",
    "for factor in range(1, rank+1):\n",
    "    plot_df = pd.DataFrame(form_plotting_B(B,factor-1,tensor.shape[1], tensor.shape[2]).T, index=agg_dfs[0].columns, columns=new_groups)\n",
    "    \n",
    "    p = np.percentile(plot_df.abs().max(axis=1).values, percentile)\n",
    "    top_n = plot_df.abs().max(axis=1).sort_values(ascending=False)\n",
    "    top_n = top_n[top_n >= p].index.tolist()\n",
    "    factor_genes[f'Factor {factor}'] = top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_sum = {'shared' : ['Factor 5', 'Factor 6'],\n",
    "              'mes_CYGB' : ['Factor 1'], \n",
    "              'mes_KCNB2' : ['Factor 2', 'Factor 3', 'Factor 4']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "factor_sum_genes = defaultdict(set)\n",
    "total_genes = set()\n",
    "\n",
    "for case in ['shared', 'mes_CYGB', 'mes_KCNB2']:\n",
    "    for f in factor_sum[case]:\n",
    "        for g in factor_genes[f]:\n",
    "            if g not in factor_sum_genes['shared']:\n",
    "                factor_sum_genes[case].add(g)\n",
    "            total_genes.add(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = 'mes_CYGB'\n",
    "ct2 = 'mes_KCNB2'\n",
    "t1 = pd.concat([df.loc[[ct1], list(total_genes)].rename(index={ct1 : '_'.join([ct1, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "t2 = pd.concat([df.loc[[ct2], list(total_genes)].rename(index={ct2 : '_'.join([ct2, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "plot_df = pd.concat([t1, t2]).T.drop_duplicates()\n",
    "\n",
    "cm = sns.clustermap(plot_df, cmap='Reds', col_cluster=False, row_cluster=True, yticklabels=1, figsize=(9, 30), standard_scale=0,\n",
    "                    cbar_kws={\"shrink\": 0.5, \"label\": \"Scaled Expression\", \"location\" : \"left\"},  # Reduce colorbar size\n",
    "                    dendrogram_ratio=(.1, .2),  # Adjust dendrogram sizes (left, top)\n",
    "                    cbar_pos=(0.02, 0.85, .03, .1),  # Adjust colorbar position (left, bottom, width, height),\n",
    "                    method='ward'\n",
    "                   )\n",
    "\n",
    "\n",
    "cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xmajorticklabels(), fontsize = 16)\n",
    "cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_ymajorticklabels(), fontsize = 6)\n",
    "\n",
    "plt.savefig(f'{folder}/Plot-Expression-All.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.to_csv(f'{folder}/DataFrame-tPARAFAC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = 'mes_CYGB'\n",
    "ct2 = 'mes_KCNB2'\n",
    "t1 = pd.concat([df.loc[[ct1], list(factor_sum_genes['shared'])].rename(index={ct1 : '_'.join([ct1, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "t2 = pd.concat([df.loc[[ct2], list(factor_sum_genes['shared'])].rename(index={ct2 : '_'.join([ct2, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "plot_df = pd.concat([t1, t2]).T.drop_duplicates()\n",
    "\n",
    "cm = sns.clustermap(plot_df, cmap='Reds', col_cluster=False, row_cluster=True, yticklabels=1, figsize=(9, 24), standard_scale=0,\n",
    "                    cbar_kws={\"shrink\": 0.5, \"label\": \"Scaled Expression\", \"location\" : \"left\"},  # Reduce colorbar size\n",
    "                    dendrogram_ratio=(.1, .2),  # Adjust dendrogram sizes (left, top)\n",
    "                    cbar_pos=(0.02, 0.85, .03, .1),  # Adjust colorbar position (left, bottom, width, height)\n",
    "                   )\n",
    "\n",
    "\n",
    "cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xmajorticklabels(), fontsize = 16)\n",
    "cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_ymajorticklabels(), fontsize = 6)\n",
    "\n",
    "plt.savefig(f'{folder}/Plot-Expression-shared.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = 'mes_CYGB'\n",
    "ct2 = 'mes_KCNB2'\n",
    "t1 = pd.concat([df.loc[[ct1], list(factor_sum_genes[ct1])].rename(index={ct1 : '_'.join([ct1, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "t2 = pd.concat([df.loc[[ct2], list(factor_sum_genes[ct1])].rename(index={ct2 : '_'.join([ct2, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "plot_df = pd.concat([t1, t2]).T.drop_duplicates()\n",
    "\n",
    "cm = sns.clustermap(plot_df, cmap='Reds', col_cluster=False, row_cluster=True, yticklabels=1, figsize=(9, 24), standard_scale=0,\n",
    "                    cbar_kws={\"shrink\": 0.5, \"label\": \"Scaled Expression\", \"location\" : \"left\"},  # Reduce colorbar size\n",
    "                    dendrogram_ratio=(.1, .2),  # Adjust dendrogram sizes (left, top)\n",
    "                    cbar_pos=(0.02, 0.85, .03, .1),  # Adjust colorbar position (left, bottom, width, height)\n",
    "                   )\n",
    "\n",
    "\n",
    "cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xmajorticklabels(), fontsize = 16)\n",
    "cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_ymajorticklabels(), fontsize = 6)\n",
    "\n",
    "plt.savefig(f'{folder}/Plot-Expression-thy_Lumen-forming.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = 'mes_CYGB'\n",
    "ct2 = 'mes_KCNB2'\n",
    "t1 = pd.concat([df.loc[[ct1], list(factor_sum_genes[ct2])].rename(index={ct1 : '_'.join([ct1, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "t2 = pd.concat([df.loc[[ct2], list(factor_sum_genes[ct2])].rename(index={ct2 : '_'.join([ct2, month])}) for df, month in zip(agg_dfs, new_groups)])\n",
    "plot_df = pd.concat([t1, t2]).T.drop_duplicates()\n",
    "\n",
    "cm = sns.clustermap(plot_df, cmap='Reds', col_cluster=False, row_cluster=True, yticklabels=1, figsize=(9, 24), standard_scale=0,\n",
    "                    cbar_kws={\"shrink\": 0.5, \"label\": \"Scaled Expression\", \"location\" : \"left\"},  # Reduce colorbar size\n",
    "                    dendrogram_ratio=(.1, .2),  # Adjust dendrogram sizes (left, top)\n",
    "                    cbar_pos=(0.02, 0.85, .03, .1),  # Adjust colorbar position (left, bottom, width, height)\n",
    "                   )\n",
    "\n",
    "\n",
    "cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xmajorticklabels(), fontsize = 16)\n",
    "cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_ymajorticklabels(), fontsize = 6)\n",
    "\n",
    "plt.savefig(f'{folder}/Plot-Expression-thy_TH_processing.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{folder}/Genes-{date}.pkl', 'wb') as f:\n",
    "    pickle.dump(factor_sum_genes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'SLC5A5' in [g for v in factor_sum_genes.values() for g in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (single_cell)",
   "language": "python",
   "name": "single_cell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
